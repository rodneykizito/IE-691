{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: \n",
    "### Added another column called \"lpsa2\" which converts the regular \"lpsa\" into categorical data.\n",
    "### This was done because I used a Random Forest classifier for the Forward Stepwise Selection.\n",
    "### Python does not have a package that performs regular stepwise selection on continuous data, which \"lpsa\" is. The following is how I converted \"lpsa\" to \"lpsa2\":\n",
    "### For \"lpsa2\", If \"lpsa\"<1, then 1; If 1<=\"lpsa\"<2, then 2; ... If 5<=\"lpsa\"<6, then 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0    lcavol   lweight  age      lbph  svi       lcp  gleason  \\\n",
      "0            1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6   \n",
      "1            2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6   \n",
      "2            3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7   \n",
      "3            4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6   \n",
      "4            5  0.751416  3.432373   62 -1.386294    0 -1.386294        6   \n",
      "5            6 -1.049822  3.228826   50 -1.386294    0 -1.386294        6   \n",
      "6            8  0.693147  3.539509   58  1.536867    0 -1.386294        6   \n",
      "7           11  0.254642  3.604138   65 -1.386294    0 -1.386294        6   \n",
      "8           12 -1.347074  3.598681   63  1.266948    0 -1.386294        6   \n",
      "9           13  1.613430  3.022861   63 -1.386294    0 -0.597837        7   \n",
      "10          14  1.477049  2.998229   67 -1.386294    0 -1.386294        7   \n",
      "11          16  1.541159  3.061052   66 -1.386294    0 -1.386294        6   \n",
      "12          17 -0.415515  3.516013   70  1.244155    0 -0.597837        7   \n",
      "13          18  2.288486  3.649359   66 -1.386294    0  0.371564        6   \n",
      "14          19 -0.562119  3.267666   41 -1.386294    0 -1.386294        6   \n",
      "15          20  0.182322  3.825375   70  1.658228    0 -1.386294        6   \n",
      "16          21  1.147402  3.419365   59 -1.386294    0 -1.386294        6   \n",
      "17          23 -0.544727  3.375880   59 -0.798508    0 -1.386294        6   \n",
      "18          24  1.781709  3.451574   63  0.438255    0  1.178655        7   \n",
      "19          27  0.512824  3.719651   65 -1.386294    0 -0.798508        7   \n",
      "20          29  1.040277  3.128951   67  0.223144    0  0.048790        7   \n",
      "21          30  2.409644  3.375880   65 -1.386294    0  1.619388        6   \n",
      "22          31  0.285179  4.090169   65  1.962908    0 -0.798508        6   \n",
      "23          33  1.275363  3.037354   71  1.266948    0 -1.386294        6   \n",
      "24          35 -0.010050  3.216874   63 -1.386294    0 -0.798508        6   \n",
      "25          37  1.423108  3.657131   73 -0.579819    0  1.658228        8   \n",
      "26          38  0.457425  2.374906   64 -1.386294    0 -1.386294        7   \n",
      "27          39  2.660959  4.085136   68  1.373716    1  1.832581        7   \n",
      "28          40  0.797507  3.013081   56  0.936093    0 -0.162519        7   \n",
      "29          41  0.620576  3.141995   60 -1.386294    0 -1.386294        9   \n",
      "..         ...       ...       ...  ...       ...  ...       ...      ...   \n",
      "37          58  0.463734  3.764682   49  1.423108    0 -1.386294        6   \n",
      "38          59  0.542324  4.178226   70  0.438255    0 -1.386294        7   \n",
      "39          60  1.061257  3.851211   61  1.294727    0 -1.386294        7   \n",
      "40          61  0.457425  4.524502   73  2.326302    0 -1.386294        6   \n",
      "41          63  2.775709  3.524889   72 -1.386294    0  1.558145        9   \n",
      "42          67  2.022871  3.878466   68  1.783391    0  1.321756        7   \n",
      "43          68  2.198335  4.050915   72  2.307573    0 -0.430783        7   \n",
      "44          69 -0.446287  4.408547   69 -1.386294    0 -1.386294        6   \n",
      "45          70  1.193922  4.780383   72  2.326302    0 -0.798508        7   \n",
      "46          71  1.864080  3.593194   60 -1.386294    1  1.321756        7   \n",
      "47          72  1.160021  3.341093   77  1.749200    0 -1.386294        7   \n",
      "48          75  2.999226  3.849083   69 -1.386294    1  1.909542        7   \n",
      "49          76  3.141130  3.263849   68 -0.051293    1  2.420368        7   \n",
      "50          77  2.010895  4.433789   72  2.122262    0  0.500775        7   \n",
      "51          78  2.537657  4.354784   78  2.326302    0 -1.386294        7   \n",
      "52          79  2.648300  3.582129   69 -1.386294    1  2.583998        7   \n",
      "53          81  1.467874  3.070376   66  0.559616    0  0.223144        7   \n",
      "54          82  2.513656  3.473518   57  0.438255    0  2.327278        7   \n",
      "55          83  2.613007  3.888754   77 -0.527633    1  0.559616        7   \n",
      "56          85  1.562346  3.709907   60  1.695616    0  0.810930        7   \n",
      "57          86  3.302849  3.518980   64 -1.386294    1  2.327278        7   \n",
      "58          87  2.024193  3.731699   58  1.638997    0 -1.386294        6   \n",
      "59          88  1.731656  3.369018   62 -1.386294    1  0.300105        7   \n",
      "60          89  2.807594  4.718052   65 -1.386294    1  2.463853        7   \n",
      "61          90  1.562346  3.695110   76  0.936093    1  0.810930        7   \n",
      "62          91  3.246491  4.101817   68 -1.386294    0 -1.386294        6   \n",
      "63          92  2.532903  3.677566   61  1.348073    1 -1.386294        7   \n",
      "64          93  2.830268  3.876396   68 -1.386294    1  1.321756        7   \n",
      "65          94  3.821004  3.896909   44 -1.386294    1  2.169054        7   \n",
      "66          96  2.882564  3.773910   68  1.558145    1  1.558145        7   \n",
      "\n",
      "    pgg45      lpsa train  lpsa2  \n",
      "0       0 -0.430783     T      1  \n",
      "1       0 -0.162519     T      1  \n",
      "2      20 -0.162519     T      1  \n",
      "3       0 -0.162519     T      1  \n",
      "4       0  0.371564     T      1  \n",
      "5       0  0.765468     T      1  \n",
      "6       0  0.854415     T      1  \n",
      "7       0  1.266948     T      2  \n",
      "8       0  1.266948     T      2  \n",
      "9      30  1.266948     T      2  \n",
      "10      5  1.348073     T      2  \n",
      "11      0  1.446919     T      2  \n",
      "12     30  1.470176     T      2  \n",
      "13      0  1.492904     T      2  \n",
      "14      0  1.558145     T      2  \n",
      "15      0  1.599388     T      2  \n",
      "16      0  1.638997     T      2  \n",
      "17      0  1.695616     T      2  \n",
      "18     60  1.713798     T      2  \n",
      "19     70  1.800058     T      2  \n",
      "20     80  1.848455     T      2  \n",
      "21      0  1.894617     T      2  \n",
      "22      0  1.924249     T      2  \n",
      "23      0  2.008214     T      3  \n",
      "24      0  2.047693     T      3  \n",
      "25     15  2.157559     T      3  \n",
      "26     15  2.191654     T      3  \n",
      "27     35  2.213754     T      3  \n",
      "28      5  2.277267     T      3  \n",
      "29     80  2.297573     T      3  \n",
      "..    ...       ...   ...    ...  \n",
      "37      0  2.794228     T      3  \n",
      "38     20  2.806386     T      3  \n",
      "39     40  2.812410     T      3  \n",
      "40      0  2.841998     T      3  \n",
      "41     95  2.853592     T      3  \n",
      "42     70  2.920470     T      3  \n",
      "43     10  2.962692     T      3  \n",
      "44      0  2.962692     T      3  \n",
      "45      5  2.972975     T      3  \n",
      "46     60  3.013081     T      4  \n",
      "47     25  3.037354     T      4  \n",
      "48     20  3.275256     T      4  \n",
      "49     50  3.337547     T      4  \n",
      "50     60  3.392829     T      4  \n",
      "51     10  3.435599     T      4  \n",
      "52     70  3.457893     T      4  \n",
      "53     40  3.516013     T      4  \n",
      "54     60  3.530763     T      4  \n",
      "55     30  3.565298     T      4  \n",
      "56     30  3.587677     T      4  \n",
      "57     60  3.630986     T      4  \n",
      "58      0  3.680091     T      4  \n",
      "59     30  3.712352     T      4  \n",
      "60     60  3.984344     T      4  \n",
      "61     75  3.993603     T      4  \n",
      "62      0  4.029806     T      5  \n",
      "63     15  4.129551     T      5  \n",
      "64     60  4.385147     T      5  \n",
      "65     40  4.684443     T      5  \n",
      "66     80  5.477509     T      6  \n",
      "\n",
      "[67 rows x 12 columns]\n",
      "    Unnamed: 0    lcavol   lweight  age      lbph  svi       lcp  gleason  \\\n",
      "0            7  0.737164  3.473518   64  0.615186    0 -1.386294        6   \n",
      "1            9 -0.776529  3.539509   47 -1.386294    0 -1.386294        6   \n",
      "2           10  0.223144  3.244544   63 -1.386294    0 -1.386294        6   \n",
      "3           15  1.205971  3.442019   57 -1.386294    0 -0.430783        7   \n",
      "4           22  2.059239  3.501043   60  1.474763    0  1.348073        7   \n",
      "5           25  0.385262  3.667400   69  1.599388    0 -1.386294        6   \n",
      "6           26  1.446919  3.124565   68  0.300105    0 -1.386294        6   \n",
      "7           28 -0.400478  3.865979   67  1.816452    0 -1.386294        7   \n",
      "8           32  0.182322  3.804438   65  1.704748    0 -1.386294        6   \n",
      "9           34  0.009950  3.267666   54 -1.386294    0 -1.386294        6   \n",
      "10          36  1.308333  4.119850   64  2.171337    0 -1.386294        7   \n",
      "11          42  1.442202  3.682610   68 -1.386294    0 -1.386294        7   \n",
      "12          44  1.771557  3.896909   61 -1.386294    0  0.810930        7   \n",
      "13          48  1.163151  4.035125   68  1.713798    0 -0.430783        7   \n",
      "14          49  1.745716  3.498022   43 -1.386294    0 -1.386294        6   \n",
      "15          50  1.220830  3.568123   70  1.373716    0 -0.798508        6   \n",
      "16          53  0.512824  3.633631   64  1.492904    0  0.048790        7   \n",
      "17          54  2.127041  4.121473   68  1.766442    0  1.446919        7   \n",
      "18          55  3.153590  3.516013   59 -1.386294    0 -1.386294        7   \n",
      "19          57  0.974560  2.865054   47 -1.386294    0  0.500775        7   \n",
      "20          62  1.997418  3.719651   63  1.619388    1  1.909542        7   \n",
      "21          64  2.034706  3.917011   66  2.008214    1  2.110213        7   \n",
      "22          65  2.073172  3.623007   64 -1.386294    0 -1.386294        6   \n",
      "23          66  1.458615  3.836221   61  1.321756    0 -0.430783        7   \n",
      "24          73  1.214913  3.825375   69 -1.386294    1  0.223144        7   \n",
      "25          74  1.838961  3.236716   60  0.438255    1  1.178655        9   \n",
      "26          80  2.779440  3.823192   63 -1.386294    0  0.371564        7   \n",
      "27          84  2.677591  3.838376   65  1.115142    0  1.749200        9   \n",
      "28          95  2.907447  3.396185   52 -1.386294    1  2.463853        7   \n",
      "29          97  3.471966  3.974998   68  0.438255    1  2.904165        7   \n",
      "\n",
      "    pgg45      lpsa train  lpsa2  \n",
      "0       0  0.765468     F      1  \n",
      "1       0  1.047319     F      2  \n",
      "2       0  1.047319     F      2  \n",
      "3       5  1.398717     F      2  \n",
      "4      20  1.658228     F      2  \n",
      "5       0  1.731656     F      2  \n",
      "6       0  1.766442     F      2  \n",
      "7      20  1.816452     F      2  \n",
      "8       0  2.008214     F      3  \n",
      "9       0  2.021548     F      3  \n",
      "10      5  2.085672     F      3  \n",
      "11     10  2.307573     F      3  \n",
      "12      6  2.374906     F      3  \n",
      "13     40  2.568788     F      3  \n",
      "14      0  2.591516     F      3  \n",
      "15      0  2.591516     F      3  \n",
      "16     70  2.684440     F      3  \n",
      "17     40  2.691243     F      3  \n",
      "18      5  2.704711     F      3  \n",
      "19      4  2.788093     F      3  \n",
      "20     40  2.853592     F      3  \n",
      "21     60  2.882004     F      3  \n",
      "22      0  2.882004     F      3  \n",
      "23     20  2.887590     F      3  \n",
      "24     20  3.056357     F      4  \n",
      "25     90  3.075006     F      4  \n",
      "26     50  3.513037     F      4  \n",
      "27     70  3.570940     F      4  \n",
      "28     10  5.143124     F      6  \n",
      "29     20  5.582932     F      6  \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('/Users/rodney/Documents/Jupyter/HW_IE_691/HW_1/PCD_Train_2.csv')\n",
    "df2 = pd.read_csv('/Users/rodney/Documents/Jupyter/HW_IE_691/HW_1/PCD_Test_2.csv')\n",
    "\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0    lcavol   lweight  age      lbph  svi       lcp  gleason  \\\n",
      "0            1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6   \n",
      "1            2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6   \n",
      "2            3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7   \n",
      "3            4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6   \n",
      "4            5  0.751416  3.432373   62 -1.386294    0 -1.386294        6   \n",
      "5            6 -1.049822  3.228826   50 -1.386294    0 -1.386294        6   \n",
      "6            8  0.693147  3.539509   58  1.536867    0 -1.386294        6   \n",
      "7           11  0.254642  3.604138   65 -1.386294    0 -1.386294        6   \n",
      "8           12 -1.347074  3.598681   63  1.266948    0 -1.386294        6   \n",
      "9           13  1.613430  3.022861   63 -1.386294    0 -0.597837        7   \n",
      "10          14  1.477049  2.998229   67 -1.386294    0 -1.386294        7   \n",
      "11          16  1.541159  3.061052   66 -1.386294    0 -1.386294        6   \n",
      "12          17 -0.415515  3.516013   70  1.244155    0 -0.597837        7   \n",
      "13          18  2.288486  3.649359   66 -1.386294    0  0.371564        6   \n",
      "14          19 -0.562119  3.267666   41 -1.386294    0 -1.386294        6   \n",
      "15          20  0.182322  3.825375   70  1.658228    0 -1.386294        6   \n",
      "16          21  1.147402  3.419365   59 -1.386294    0 -1.386294        6   \n",
      "17          23 -0.544727  3.375880   59 -0.798508    0 -1.386294        6   \n",
      "18          24  1.781709  3.451574   63  0.438255    0  1.178655        7   \n",
      "19          27  0.512824  3.719651   65 -1.386294    0 -0.798508        7   \n",
      "20          29  1.040277  3.128951   67  0.223144    0  0.048790        7   \n",
      "21          30  2.409644  3.375880   65 -1.386294    0  1.619388        6   \n",
      "22          31  0.285179  4.090169   65  1.962908    0 -0.798508        6   \n",
      "23          33  1.275363  3.037354   71  1.266948    0 -1.386294        6   \n",
      "24          35 -0.010050  3.216874   63 -1.386294    0 -0.798508        6   \n",
      "25          37  1.423108  3.657131   73 -0.579819    0  1.658228        8   \n",
      "26          38  0.457425  2.374906   64 -1.386294    0 -1.386294        7   \n",
      "27          39  2.660959  4.085136   68  1.373716    1  1.832581        7   \n",
      "28          40  0.797507  3.013081   56  0.936093    0 -0.162519        7   \n",
      "29          41  0.620576  3.141995   60 -1.386294    0 -1.386294        9   \n",
      "..         ...       ...       ...  ...       ...  ...       ...      ...   \n",
      "37          58  0.463734  3.764682   49  1.423108    0 -1.386294        6   \n",
      "38          59  0.542324  4.178226   70  0.438255    0 -1.386294        7   \n",
      "39          60  1.061257  3.851211   61  1.294727    0 -1.386294        7   \n",
      "40          61  0.457425  4.524502   73  2.326302    0 -1.386294        6   \n",
      "41          63  2.775709  3.524889   72 -1.386294    0  1.558145        9   \n",
      "42          67  2.022871  3.878466   68  1.783391    0  1.321756        7   \n",
      "43          68  2.198335  4.050915   72  2.307573    0 -0.430783        7   \n",
      "44          69 -0.446287  4.408547   69 -1.386294    0 -1.386294        6   \n",
      "45          70  1.193922  4.780383   72  2.326302    0 -0.798508        7   \n",
      "46          71  1.864080  3.593194   60 -1.386294    1  1.321756        7   \n",
      "47          72  1.160021  3.341093   77  1.749200    0 -1.386294        7   \n",
      "48          75  2.999226  3.849083   69 -1.386294    1  1.909542        7   \n",
      "49          76  3.141130  3.263849   68 -0.051293    1  2.420368        7   \n",
      "50          77  2.010895  4.433789   72  2.122262    0  0.500775        7   \n",
      "51          78  2.537657  4.354784   78  2.326302    0 -1.386294        7   \n",
      "52          79  2.648300  3.582129   69 -1.386294    1  2.583998        7   \n",
      "53          81  1.467874  3.070376   66  0.559616    0  0.223144        7   \n",
      "54          82  2.513656  3.473518   57  0.438255    0  2.327278        7   \n",
      "55          83  2.613007  3.888754   77 -0.527633    1  0.559616        7   \n",
      "56          85  1.562346  3.709907   60  1.695616    0  0.810930        7   \n",
      "57          86  3.302849  3.518980   64 -1.386294    1  2.327278        7   \n",
      "58          87  2.024193  3.731699   58  1.638997    0 -1.386294        6   \n",
      "59          88  1.731656  3.369018   62 -1.386294    1  0.300105        7   \n",
      "60          89  2.807594  4.718052   65 -1.386294    1  2.463853        7   \n",
      "61          90  1.562346  3.695110   76  0.936093    1  0.810930        7   \n",
      "62          91  3.246491  4.101817   68 -1.386294    0 -1.386294        6   \n",
      "63          92  2.532903  3.677566   61  1.348073    1 -1.386294        7   \n",
      "64          93  2.830268  3.876396   68 -1.386294    1  1.321756        7   \n",
      "65          94  3.821004  3.896909   44 -1.386294    1  2.169054        7   \n",
      "66          96  2.882564  3.773910   68  1.558145    1  1.558145        7   \n",
      "\n",
      "    pgg45  lpsa2  \n",
      "0       0      1  \n",
      "1       0      1  \n",
      "2      20      1  \n",
      "3       0      1  \n",
      "4       0      1  \n",
      "5       0      1  \n",
      "6       0      1  \n",
      "7       0      2  \n",
      "8       0      2  \n",
      "9      30      2  \n",
      "10      5      2  \n",
      "11      0      2  \n",
      "12     30      2  \n",
      "13      0      2  \n",
      "14      0      2  \n",
      "15      0      2  \n",
      "16      0      2  \n",
      "17      0      2  \n",
      "18     60      2  \n",
      "19     70      2  \n",
      "20     80      2  \n",
      "21      0      2  \n",
      "22      0      2  \n",
      "23      0      3  \n",
      "24      0      3  \n",
      "25     15      3  \n",
      "26     15      3  \n",
      "27     35      3  \n",
      "28      5      3  \n",
      "29     80      3  \n",
      "..    ...    ...  \n",
      "37      0      3  \n",
      "38     20      3  \n",
      "39     40      3  \n",
      "40      0      3  \n",
      "41     95      3  \n",
      "42     70      3  \n",
      "43     10      3  \n",
      "44      0      3  \n",
      "45      5      3  \n",
      "46     60      4  \n",
      "47     25      4  \n",
      "48     20      4  \n",
      "49     50      4  \n",
      "50     60      4  \n",
      "51     10      4  \n",
      "52     70      4  \n",
      "53     40      4  \n",
      "54     60      4  \n",
      "55     30      4  \n",
      "56     30      4  \n",
      "57     60      4  \n",
      "58      0      4  \n",
      "59     30      4  \n",
      "60     60      4  \n",
      "61     75      4  \n",
      "62      0      5  \n",
      "63     15      5  \n",
      "64     60      5  \n",
      "65     40      5  \n",
      "66     80      6  \n",
      "\n",
      "[67 rows x 10 columns]\n",
      "    Unnamed: 0    lcavol   lweight  age      lbph  svi       lcp  gleason  \\\n",
      "0            7  0.737164  3.473518   64  0.615186    0 -1.386294        6   \n",
      "1            9 -0.776529  3.539509   47 -1.386294    0 -1.386294        6   \n",
      "2           10  0.223144  3.244544   63 -1.386294    0 -1.386294        6   \n",
      "3           15  1.205971  3.442019   57 -1.386294    0 -0.430783        7   \n",
      "4           22  2.059239  3.501043   60  1.474763    0  1.348073        7   \n",
      "5           25  0.385262  3.667400   69  1.599388    0 -1.386294        6   \n",
      "6           26  1.446919  3.124565   68  0.300105    0 -1.386294        6   \n",
      "7           28 -0.400478  3.865979   67  1.816452    0 -1.386294        7   \n",
      "8           32  0.182322  3.804438   65  1.704748    0 -1.386294        6   \n",
      "9           34  0.009950  3.267666   54 -1.386294    0 -1.386294        6   \n",
      "10          36  1.308333  4.119850   64  2.171337    0 -1.386294        7   \n",
      "11          42  1.442202  3.682610   68 -1.386294    0 -1.386294        7   \n",
      "12          44  1.771557  3.896909   61 -1.386294    0  0.810930        7   \n",
      "13          48  1.163151  4.035125   68  1.713798    0 -0.430783        7   \n",
      "14          49  1.745716  3.498022   43 -1.386294    0 -1.386294        6   \n",
      "15          50  1.220830  3.568123   70  1.373716    0 -0.798508        6   \n",
      "16          53  0.512824  3.633631   64  1.492904    0  0.048790        7   \n",
      "17          54  2.127041  4.121473   68  1.766442    0  1.446919        7   \n",
      "18          55  3.153590  3.516013   59 -1.386294    0 -1.386294        7   \n",
      "19          57  0.974560  2.865054   47 -1.386294    0  0.500775        7   \n",
      "20          62  1.997418  3.719651   63  1.619388    1  1.909542        7   \n",
      "21          64  2.034706  3.917011   66  2.008214    1  2.110213        7   \n",
      "22          65  2.073172  3.623007   64 -1.386294    0 -1.386294        6   \n",
      "23          66  1.458615  3.836221   61  1.321756    0 -0.430783        7   \n",
      "24          73  1.214913  3.825375   69 -1.386294    1  0.223144        7   \n",
      "25          74  1.838961  3.236716   60  0.438255    1  1.178655        9   \n",
      "26          80  2.779440  3.823192   63 -1.386294    0  0.371564        7   \n",
      "27          84  2.677591  3.838376   65  1.115142    0  1.749200        9   \n",
      "28          95  2.907447  3.396185   52 -1.386294    1  2.463853        7   \n",
      "29          97  3.471966  3.974998   68  0.438255    1  2.904165        7   \n",
      "\n",
      "    pgg45  lpsa2  \n",
      "0       0      1  \n",
      "1       0      2  \n",
      "2       0      2  \n",
      "3       5      2  \n",
      "4      20      2  \n",
      "5       0      2  \n",
      "6       0      2  \n",
      "7      20      2  \n",
      "8       0      3  \n",
      "9       0      3  \n",
      "10      5      3  \n",
      "11     10      3  \n",
      "12      6      3  \n",
      "13     40      3  \n",
      "14      0      3  \n",
      "15      0      3  \n",
      "16     70      3  \n",
      "17     40      3  \n",
      "18      5      3  \n",
      "19      4      3  \n",
      "20     40      3  \n",
      "21     60      3  \n",
      "22      0      3  \n",
      "23     20      3  \n",
      "24     20      4  \n",
      "25     90      4  \n",
      "26     50      4  \n",
      "27     70      4  \n",
      "28     10      6  \n",
      "29     20      6  \n"
     ]
    }
   ],
   "source": [
    "df1 = df1.drop(columns=['train','lpsa'])\n",
    "df2 = df2.drop(columns=['train','lpsa'])\n",
    "\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45\n",
      "0  -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0\n",
      "1  -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0\n",
      "2  -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20\n",
      "3  -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0\n",
      "4   0.751416  3.432373   62 -1.386294    0 -1.386294        6      0\n",
      "5  -1.049822  3.228826   50 -1.386294    0 -1.386294        6      0\n",
      "6   0.693147  3.539509   58  1.536867    0 -1.386294        6      0\n",
      "7   0.254642  3.604138   65 -1.386294    0 -1.386294        6      0\n",
      "8  -1.347074  3.598681   63  1.266948    0 -1.386294        6      0\n",
      "9   1.613430  3.022861   63 -1.386294    0 -0.597837        7     30\n",
      "10  1.477049  2.998229   67 -1.386294    0 -1.386294        7      5\n",
      "11  1.541159  3.061052   66 -1.386294    0 -1.386294        6      0\n",
      "12 -0.415515  3.516013   70  1.244155    0 -0.597837        7     30\n",
      "13  2.288486  3.649359   66 -1.386294    0  0.371564        6      0\n",
      "14 -0.562119  3.267666   41 -1.386294    0 -1.386294        6      0\n",
      "15  0.182322  3.825375   70  1.658228    0 -1.386294        6      0\n",
      "16  1.147402  3.419365   59 -1.386294    0 -1.386294        6      0\n",
      "17 -0.544727  3.375880   59 -0.798508    0 -1.386294        6      0\n",
      "18  1.781709  3.451574   63  0.438255    0  1.178655        7     60\n",
      "19  0.512824  3.719651   65 -1.386294    0 -0.798508        7     70\n",
      "20  1.040277  3.128951   67  0.223144    0  0.048790        7     80\n",
      "21  2.409644  3.375880   65 -1.386294    0  1.619388        6      0\n",
      "22  0.285179  4.090169   65  1.962908    0 -0.798508        6      0\n",
      "23  1.275363  3.037354   71  1.266948    0 -1.386294        6      0\n",
      "24 -0.010050  3.216874   63 -1.386294    0 -0.798508        6      0\n",
      "25  1.423108  3.657131   73 -0.579819    0  1.658228        8     15\n",
      "26  0.457425  2.374906   64 -1.386294    0 -1.386294        7     15\n",
      "27  2.660959  4.085136   68  1.373716    1  1.832581        7     35\n",
      "28  0.797507  3.013081   56  0.936093    0 -0.162519        7      5\n",
      "29  0.620576  3.141995   60 -1.386294    0 -1.386294        9     80\n",
      "..       ...       ...  ...       ...  ...       ...      ...    ...\n",
      "37  0.463734  3.764682   49  1.423108    0 -1.386294        6      0\n",
      "38  0.542324  4.178226   70  0.438255    0 -1.386294        7     20\n",
      "39  1.061257  3.851211   61  1.294727    0 -1.386294        7     40\n",
      "40  0.457425  4.524502   73  2.326302    0 -1.386294        6      0\n",
      "41  2.775709  3.524889   72 -1.386294    0  1.558145        9     95\n",
      "42  2.022871  3.878466   68  1.783391    0  1.321756        7     70\n",
      "43  2.198335  4.050915   72  2.307573    0 -0.430783        7     10\n",
      "44 -0.446287  4.408547   69 -1.386294    0 -1.386294        6      0\n",
      "45  1.193922  4.780383   72  2.326302    0 -0.798508        7      5\n",
      "46  1.864080  3.593194   60 -1.386294    1  1.321756        7     60\n",
      "47  1.160021  3.341093   77  1.749200    0 -1.386294        7     25\n",
      "48  2.999226  3.849083   69 -1.386294    1  1.909542        7     20\n",
      "49  3.141130  3.263849   68 -0.051293    1  2.420368        7     50\n",
      "50  2.010895  4.433789   72  2.122262    0  0.500775        7     60\n",
      "51  2.537657  4.354784   78  2.326302    0 -1.386294        7     10\n",
      "52  2.648300  3.582129   69 -1.386294    1  2.583998        7     70\n",
      "53  1.467874  3.070376   66  0.559616    0  0.223144        7     40\n",
      "54  2.513656  3.473518   57  0.438255    0  2.327278        7     60\n",
      "55  2.613007  3.888754   77 -0.527633    1  0.559616        7     30\n",
      "56  1.562346  3.709907   60  1.695616    0  0.810930        7     30\n",
      "57  3.302849  3.518980   64 -1.386294    1  2.327278        7     60\n",
      "58  2.024193  3.731699   58  1.638997    0 -1.386294        6      0\n",
      "59  1.731656  3.369018   62 -1.386294    1  0.300105        7     30\n",
      "60  2.807594  4.718052   65 -1.386294    1  2.463853        7     60\n",
      "61  1.562346  3.695110   76  0.936093    1  0.810930        7     75\n",
      "62  3.246491  4.101817   68 -1.386294    0 -1.386294        6      0\n",
      "63  2.532903  3.677566   61  1.348073    1 -1.386294        7     15\n",
      "64  2.830268  3.876396   68 -1.386294    1  1.321756        7     60\n",
      "65  3.821004  3.896909   44 -1.386294    1  2.169054        7     40\n",
      "66  2.882564  3.773910   68  1.558145    1  1.558145        7     80\n",
      "\n",
      "[67 rows x 8 columns]\n",
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     2\n",
      "8     2\n",
      "9     2\n",
      "10    2\n",
      "11    2\n",
      "12    2\n",
      "13    2\n",
      "14    2\n",
      "15    2\n",
      "16    2\n",
      "17    2\n",
      "18    2\n",
      "19    2\n",
      "20    2\n",
      "21    2\n",
      "22    2\n",
      "23    3\n",
      "24    3\n",
      "25    3\n",
      "26    3\n",
      "27    3\n",
      "28    3\n",
      "29    3\n",
      "     ..\n",
      "37    3\n",
      "38    3\n",
      "39    3\n",
      "40    3\n",
      "41    3\n",
      "42    3\n",
      "43    3\n",
      "44    3\n",
      "45    3\n",
      "46    4\n",
      "47    4\n",
      "48    4\n",
      "49    4\n",
      "50    4\n",
      "51    4\n",
      "52    4\n",
      "53    4\n",
      "54    4\n",
      "55    4\n",
      "56    4\n",
      "57    4\n",
      "58    4\n",
      "59    4\n",
      "60    4\n",
      "61    4\n",
      "62    5\n",
      "63    5\n",
      "64    5\n",
      "65    5\n",
      "66    6\n",
      "Name: lpsa2, Length: 67, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train = df1[['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45']]\n",
    "y_train = df1['lpsa2']\n",
    "\n",
    "X_test = df2[['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45']]\n",
    "y_test = df2['lpsa2']\n",
    "\n",
    "print (X_train)\n",
    "print (y_train)\n",
    "# print (X_test)\n",
    "# print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (67, 8) (67,)\n",
      "Testing dataset shape: (30, 8) (30,)\n"
     ]
    }
   ],
   "source": [
    "print('Training dataset shape:', X_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE:\n",
    "### Arbitrarily selected a desired subset of size 4 predictors/features.\n",
    "### The next shell builds a random forest classifier and uses it for forward stepwise selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   11.1s finished\n",
      "\n",
      "[2018-09-06 14:40:11] Features: 1/5 -- score: 0.47130026835909183/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    9.6s finished\n",
      "\n",
      "[2018-09-06 14:40:21] Features: 2/5 -- score: 0.5475837887602594/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    8.3s finished\n",
      "\n",
      "[2018-09-06 14:40:29] Features: 3/5 -- score: 0.5113602084190318/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.8s finished\n",
      "\n",
      "[2018-09-06 14:40:36] Features: 4/5 -- score: 0.5008775538187302/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.5s finished\n",
      "\n",
      "[2018-09-06 14:40:41] Features: 5/5 -- score: 0.5533554680613504"
     ]
    }
   ],
   "source": [
    "# Build RF classifier to use in predictor/feature selection\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# Build step forward predictor/feature selection\n",
    "sfs1 = sfs(clf,\n",
    "           k_features=5,\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERPRETATION OF RESULTS:\n",
    "### The above output shows the iterations. At each iteration, the best available predictor/feature that improves the model was added to the subset.\n",
    "### The iterations stopped once 5 predictors/features were added to the subset.\n",
    "### The \"score\" displayed is the \"accuracy\" of the model with the selected predictors/features in it. The results show that the best performing model had a subset of 5 predictors/features and an accuracy score of 0.5533554680613504. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next shell displays/prints which 5 predictors/features were selected for the subset using forward piecewise selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# Which predictors/freatures?\n",
    "predictor_cols = list(sfs1.k_feature_idx_)\n",
    "print(predictor_cols)\n",
    "\n",
    "# Predictor Columns Key\n",
    "# 0 = 'lcavol' \n",
    "# 1 = 'lweight' \n",
    "# 2 = 'age'\n",
    "# 3 = 'lbph'\n",
    "# 4 = 'svi', \n",
    "# 5 = 'lcp'\n",
    "# 6 = 'gleason'\n",
    "# 7 = 'pgg45'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERPRETATION OF RESULTS:\n",
    "### The above output shows the 5 predictors/features selected as the best for the model. The feature are 'lweight', 'svi', 'lcp','gleason','pgg45' based off the Key displayed in the above shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next shell builds the full model using just the 5 selected predictors/features instead of using all 8.\n",
    "### The training and testing accuracy using the 5 selected predictors/features is printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on selected predictors/features: 0.791\n",
      "Testing accuracy on selected predictors/features: 0.400\n"
     ]
    }
   ],
   "source": [
    "# Build full model with the 5 selected predictors/features\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train[['lweight', 'svi', 'lcp','gleason','pgg45']], y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train[['lweight', 'svi', 'lcp','gleason','pgg45']])\n",
    "print('Training accuracy on selected predictors/features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test[['lweight', 'svi', 'lcp','gleason','pgg45']])\n",
    "print('Testing accuracy on selected predictors/features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next shell builds the full model using ALL the 8 predictors/features instead of using the subset of 5.\n",
    "### The training and testing accuracy using ALL predictors/features is printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on all predictors/features: 0.940\n",
      "Testing accuracy on all predictors/features: 0.500\n"
     ]
    }
   ],
   "source": [
    "# Build full model on ALL predictors/features, for comparison\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print('Training accuracy on all predictors/features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print('Testing accuracy on all predictors/features: %.3f' % acc(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
